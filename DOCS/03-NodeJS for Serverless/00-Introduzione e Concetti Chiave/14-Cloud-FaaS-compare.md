# Tabella Comparativa FaaS

| **Elemento / Caratteristica** | **AWS Lambda** | **Azure Functions** | **Google Cloud Functions / Cloud Run** | **Open-Source (Knative / OpenFaaS)** |
|---|---|---|---|---|
| **Timeout / Durata massima esecuzione** | Fino a **900 s (15 minuti)**. :contentReference[oaicite:0]{index=0} | - **Consumption plan**: default 5 min, max 10 min. :contentReference[oaicite:1]{index=1}  <br>- **Premium / Flex**: timeout “unbounded” (ma grace period durante lo scale-in) :contentReference[oaicite:2]{index=2} | - **Cloud Run (Gen v2)**: fino a **60 minuti** per HTTP. :contentReference[oaicite:3]{index=3}  <br>- **Cloud Run Functions (1st gen)**: max ~9 minuti (per alcuni trigger). :contentReference[oaicite:4]{index=4} | Dipende dall’implementazione su Kubernetes. Con Knative / OpenFaaS puoi avere funzioni lunghissime, ma sei limitato dalle risorse e dalle configurazioni del cluster. |
| **Memoria / CPU** | Memoria da **128 MB** a **10.240 MB** (10 GB), configurabile. :contentReference[oaicite:5]{index=5} | - **Consumption plan**: max ~1,5 GB di memoria per istanza. :contentReference[oaicite:6]{index=6}  <br>- **Premium**: opzioni più alte di memoria (più core / vCPU) secondo piano. :contentReference[oaicite:7]{index=7} | - **Cloud Run (Gen v2)**: fino a **16 GiB RAM** e 4 vCPU. :contentReference[oaicite:8]{index=8} <br>- **1st gen**: fino a ~8 GB RAM e 2 vCPU. :contentReference[oaicite:9]{index=9} | Molto flessibile: dipende da come configuri i pod / container su Kubernetes. Puoi allocare grandi risorse, ma devi gestire tu stesso il provisioning. |
| **Concurrency (concorrenza)** | Implicitamente, scala su invocazioni parallele; il limite di concorrenza dipende dai limiti quota. Ad esempio, il limite predefinito può essere 1.000 invocazioni simultanee / regione (ma può essere aumentato). :contentReference[oaicite:10]{index=10} | Dipende: nel **Consumption plan** le istanze sono condivise e Azure gestisce il scale-out; ci sono limiti per istanza / piano. :contentReference[oaicite:11]{index=11} | - **Cloud Run (Gen v2)**: supporta concorrenza fino a **1000 richieste per istanza**. :contentReference[oaicite:12]{index=12} <br>- **1st gen**: 1 richiesta concorrente per istanza. :contentReference[oaicite:13]{index=13} | Dipende su come configuri il sistema: su K8s puoi avere più pod, e ogni pod può gestire più richieste (se il tuo FaaS engine lo supporta). |
| **Scalabilità / Auto-scaling** | Automatico per invocazioni (scale-out), ma la concorrenza massima / limiti dipendono dalle quote e dai limiti di regione. | Azure scala automaticamente in base agli eventi / trigger, ma con **Premium** puoi avere istanze pre-warm per evitare cold start. :contentReference[oaicite:14]{index=14} | Cloud Run scala le istanze container automaticamente. Con concorrenza per istanza (in Gen v2) puoi essere molto efficiente. | Scalabilità gestita dal cluster Kubernetes: auto-scaling basato su metriche (CPU, richieste, custom), ma richiede configurazione operativa. |
| **Modello di pricing** | - Invocazioni: paghi per numero di richieste. <br>- Compute: paghi GB-secondi in base a memoria e tempo di esecuzione. :contentReference[oaicite:15]{index=15} | - **Consumption**: paghi per esecuzione + GB-s. Free grant di ~1M richieste + 400.000 GB-s. :contentReference[oaicite:16]{index=16} <br>- **Premium**: billing su base memoria e core-seconds (istanze sempre-on), non per singola invocazione. :contentReference[oaicite:17]{index=17} | - **Cloud Run (v2)**: paghi per secondo di utilizzo (GB-s e CPU) + eventuali istanze minime (idle). :contentReference[oaicite:18]{index=18} <br>- **1st gen**: metrica simile ma senza concorrenza per istanza. :contentReference[oaicite:19]{index=19} | Generalmente costi per risorse del cluster (nodi K8s, memoria, CPU), plus costi operativi (monitoring, scaling). Non “pay-per-invocazione” puro come i FaaS cloud, a meno che non usi qualcosa di molto custom. |
| **Cold start / Latency iniziale** | Cold start comune, soprattutto con runtime “pesanti” (Java, .NET, grandi bundle). Possibile mitigare con Provisioned Concurrency (istanze pre-warm). | Nel Piano **Consumption** potresti avere cold start. Nel **Premium** puoi avere istanze sempre pronte (“Always Ready”) per ridurre o eliminare il cold start. :contentReference[oaicite:20]{index=20} | Cloud Run (v2): con istanze minime configurate, puoi ridurre il tempo di risposta iniziale. Con concorrenza alta, le istanze gestiscono più richieste. | Cold start dipende da come avvii i container / pod su Kubernetes e se hai risorse pronte. Puoi mantenere replica “calda” ma richiede gestione. |
| **Trigger / Integrazioni eventi** | Ampia integrazione con ecosistema AWS: S3, DynamoDB, EventBridge, SQS, SNS, Step Functions, ecc. | Molto buone integrazioni con Azure: Service Bus, Event Hubs, Logic Apps, Durable Functions, Timer, HTTP, ecc. | Integrazione con Pub/Sub, Cloud Storage, Eventarc, HTTP trigger, ecc. Con Cloud Run hai anche flessibilità container. | Dipende: su Kubernetes puoi integrare con messaggistica, queue, API gateway, ma devi configurare da zero (o usare framework FaaS che già supportano trigger). |
| **Sicurezza / Networking** | Supporta VPC (Lambda può essere integrato in VPC), IAM molto granulare. | Supporto a VNet, Managed Identities, autenticazione Azure AD, binding di sicurezza. | Cloud Run V2 supporta VPC, controllo IAM, service account; sicurezza container. | Sicurezza definita da Kubernetes (RBAC, NetworkPolicy, TLS, segreti) — grande flessibilità ma anche complessità operativa. |
| **Uso consigliato / casi d’uso** | Microservizi event-driven, backend API, elaborazione dati, job on-demand, trasformazioni dati, automazione. | Workflow serverless con bisogno di latenza bassa, orchestrazione con Durable Functions, integrazione enterprise Microsoft, API, app event-driven. | Quando vuoi deployare container (dipendenze complesse), gestire funzioni con richieste HTTP ad alta concorrenza, workload di lunga durata, oppure integrare con eventi GCP. | Se hai già un cluster Kubernetes, vuoi evitare lock-in cloud, gestire runtime custom, o vuoi portabilità / sovranità. |

